---
title: "AC53013 KMeans Investigation"
author: "Robert Meredith"
date: "1st March 2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy} \fancyhead[C]{AC5013 Robert Meredith} \fancyfoot[C]{\thepage}
csl: harvard.csl
bibliography: kmeans.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction

I this assignment I will examine the output of multiple runs of the R K Means algorithm on the Iris dataset and dicuss how Kmeans is working on this data. I will illustrate this through the use of various visualisations.I will assume the reader knows about the KMeans algorithm and not go into choice of number of clusters.

# Initial Data Exploration

Using the code provided for this assignment we can see that if we run the loop multiple times that we get different outputs from some of the runs. The clusters are represented by different coloured points on the histogram. Above each histogram is the kmeans "tot.withinss" which is the sum of the "Vector of within-cluster sum of squares, one component per cluster" [@Datacamp]. We would like this to be as low as possible as the lower the value the more homogeneity there is in the clusters.

```{r Code_Chunk_1, echo=FALSE, results='hide'}
iris
newiris <- iris
newiris$Species <- NULL
par(mfrow = c(3,4))
for(i in 1:12) {
kc <- kmeans(newiris, 3)
plot(newiris[c("Sepal.Length", "Sepal.Width")], col=kc$cluster, main = kc$tot.withinss)
}
```

It appears from a visual inspection of this inital exploration that actually there are only two different outputs. The R kmeans algorithm sometimes chooses a different colour for the clusters but there appear to only be two results one of which is optimum as it has a lower Total Withinss.

To test for this we can compare the cluster output centres and see how many variants there are. However Kmeans does not know which cluster is cluster 1 etc so first we need to compare the cluster centres in any order using all_equal ignoring row order. Running the code 1000 times shows that we never get a third set of cluster centres as an output. 

```{r Code_Chunk_2, echo=FALSE, eval=TRUE}
suppressWarnings(suppressMessages(library(tidyverse)))
newiris <- iris
newiris$Species <- NULL
kc <- kmeans(newiris, 3)
res1count <- 0
res2count <- 0
res3count <- 0
result1 <- kc$centers 
result2 <- result1[FALSE,]

for (i in 1:1000){
  match = 0
  kc <- kmeans(newiris, 3)
  comparison <- kc$centers
  if ((all_equal(result1, comparison, ignore_col_order = TRUE, ignore_row_order = TRUE, convert = FALSE)) == TRUE){
    res1count = res1count + 1
    match = 1
  } else {
    res2count = res2count + 1
    result2 <- comparison
    match =1
  }
  if (match == 0){
    res3count = res3count + 1
  }
}

print("First set of centres is")
print(result1)
print("Count of first set of centres is:")
print(res1count)
print("Second set of centres is")
print(result2)
print("Count of second set of centres is:")
print(res2count)
print("Count of third set of centres is:")
print(res3count)
```

So it appears that depending ont he random starting points chosen by the algorithm we have just two possible answers. To see how many points end up in different clusters for these two outputs we can compare and plot the output vectors. There is a problem with this in that the cluster numbers in multiple runs of KMeans can change. Cluster 1 is not always cluster one. Looking back at the plots in the first section we can see that the 3 clusters could be described as Top Left, Bottom Left and Right in each output. 

So the first task is to enure we have two vectors where the cluster numbers are consistent across the two possible outputs. The point with the max sepal width should be in the top left cluster. The point with the max sepal length should be in the right cluster. So we will run the outputs until we match two cluster vectors that agree. We will arbitrarily say we want the top left cluster to be cluster 1 and the right cluster to be cluster 3. 




```{r Code_Chunk_3, echo=FALSE, eval=TRUE}

suppressWarnings(suppressMessages(library(tidyverse)))
newiris <- iris
newiris$Species <- NULL
row_max_width <- which.max(newiris$Sepal.Width)
print(row_max_width)
row_max_length <- which.max(newiris$Sepal.Length)
print(row_max_length)
kc <- kmeans(newiris, 3)
result1 <- kc$centers 
result2 <- result1[FALSE,]

for (i in 1:100){
  kc <- kmeans(newiris, 3)
  comparison <- kc$centers
  if ((all_equal(result1, comparison, ignore_col_order = TRUE, ignore_row_order = TRUE, convert = FALSE)) == TRUE){
    if (kc$cluster[row_max_length] == 3 && kc$cluster[row_max_width] ==1){
      type1compare = kc
    }
  } else {
    if (kc$cluster[row_max_length] == 3 && kc$cluster[row_max_width] ==1){
      type2compare = kc
    }
  }
}
print(type1compare)
print(type2compare)

```
We can now compare and plot the points that have moved between the two solutions:

```{r Code_Chunk_3, echo=FALSE, eval=TRUE}

resultvector = type1compare$cluster != type2compare$cluster 
print(resultvector)
answer = newiris[resultvector,]
notanswer = newiris[!resultvector,]
plot(answer[c("Sepal.Length", "Sepal.Width")])
plot(notanswer[c("Sepal.Length", "Sepal.Width")])


```


A fairly well known issue with the kmeans algorithm in general is that depending on the starting points chosen the algorithm "is liable to find a local minimum solution instead of a global  one, and as such may not find the  optimal partition."  [@morissette2013k]. So to investigate this further the starting points of the cluster will be plotted against the outcome. The default in the R Kmeans algorithm is that when the number of cluster are provided, in this case 3, that that number of random rows are taken from the initial dataset as the starting points. [@Datacamp]

Another feature of KMeans is that the initial points might be random by default but given a particular set of starting points the output is not random. We can demonstrate this by running the code say 100,000 time for the same starting points and seeing that the output is the same. The starting points can be provided as a matrix instead of specifying the number of clusters. So we can specify 3 random points in the four dimensional space and see what the results are.

A test with each of the algorithms provided with R Kmeans did not show any different results. The optimum result was chosen most of the time with the other result appearing about 20% of the time. The default algorithm in R Kmeans is Hartigan and Wong (1979) however "Lloyd" and "Forgy" are also available. [@Datacamp]





## References


